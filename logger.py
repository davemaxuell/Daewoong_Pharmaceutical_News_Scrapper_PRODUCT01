# ë¡œê¹… ëª¨ë“ˆ - ìŠ¤í¬ë˜í¼ ì‹¤í–‰ ê¸°ë¡ ê´€ë¦¬
# ë§¤ì¼ ì‹¤í–‰ ê²°ê³¼ë¥¼ ë¡œê·¸ íŒŒì¼ì— ì €ì¥í•˜ê³  ì¶”ì í•©ë‹ˆë‹¤.

import os
import json
from datetime import datetime
from typing import Optional

LOG_DIR = "logs"
LOG_FILE = os.path.join(LOG_DIR, "scraper_history.json")


def ensure_log_dir():
    """ë¡œê·¸ ë””ë ‰í† ë¦¬ ìƒì„±"""
    if not os.path.exists(LOG_DIR):
        os.makedirs(LOG_DIR)


def load_history() -> list:
    """ì‹¤í–‰ ê¸°ë¡ ë¡œë“œ"""
    ensure_log_dir()
    if os.path.exists(LOG_FILE):
        try:
            with open(LOG_FILE, 'r', encoding='utf-8') as f:
                return json.load(f)
        except:
            return []
    return []


def save_history(history: list):
    """ì‹¤í–‰ ê¸°ë¡ ì €ì¥"""
    ensure_log_dir()
    with open(LOG_FILE, 'w', encoding='utf-8') as f:
        json.dump(history, f, ensure_ascii=False, indent=2)


def log_execution(
    total_articles: int,
    source_stats: dict,
    classification_stats: dict,
    output_file: str,
    error: Optional[str] = None
):
    """
    ì‹¤í–‰ ê²°ê³¼ ê¸°ë¡
    
    Args:
        total_articles: ìˆ˜ì§‘ëœ ì´ ê¸°ì‚¬ ìˆ˜
        source_stats: ì†ŒìŠ¤ë³„ í†µê³„ {source_name: count}
        classification_stats: ë¶„ë¥˜ë³„ í†µê³„ {classification: count}
        output_file: ì €ì¥ëœ JSON íŒŒì¼ëª…
        error: ì˜¤ë¥˜ ë©”ì‹œì§€ (ìˆì„ ê²½ìš°)
    """
    history = load_history()
    
    entry = {
        "timestamp": datetime.now().isoformat(),
        "date": datetime.now().strftime("%Y-%m-%d"),
        "time": datetime.now().strftime("%H:%M:%S"),
        "total_articles": total_articles,
        "source_stats": source_stats,
        "classification_stats": classification_stats,
        "output_file": output_file,
        "success": error is None,
        "error": error
    }
    
    history.append(entry)
    
    # ìµœê·¼ 90ì¼ì¹˜ë§Œ ë³´ê´€
    if len(history) > 90:
        history = history[-90:]
    
    save_history(history)
    
    # ì¼ë³„ ìƒì„¸ ë¡œê·¸ë„ ì €ì¥
    daily_log_file = os.path.join(LOG_DIR, f"log_{datetime.now().strftime('%Y%m%d')}.txt")
    with open(daily_log_file, 'a', encoding='utf-8') as f:
        f.write(f"\n{'='*60}\n")
        f.write(f"ì‹¤í–‰ ì‹œê°„: {entry['timestamp']}\n")
        f.write(f"ì´ ê¸°ì‚¬ ìˆ˜: {total_articles}\n")
        f.write(f"ì¶œë ¥ íŒŒì¼: {output_file}\n")
        
        if source_stats:
            f.write("\n[ì†ŒìŠ¤ë³„ í†µê³„]\n")
            for src, count in sorted(source_stats.items(), key=lambda x: -x[1]):
                f.write(f"  - {src}: {count}ê°œ\n")
        
        if classification_stats:
            f.write("\n[ë¶„ë¥˜ë³„ í†µê³„]\n")
            for cls, count in sorted(classification_stats.items(), key=lambda x: -x[1]):
                f.write(f"  - {cls}: {count}ê°œ\n")
        
        if error:
            f.write(f"\n[ì˜¤ë¥˜] {error}\n")
        
        f.write(f"{'='*60}\n")
    
    return entry


def get_recent_executions(days: int = 7) -> list:
    """ìµœê·¼ Nì¼ê°„ ì‹¤í–‰ ê¸°ë¡ ì¡°íšŒ"""
    history = load_history()
    
    from datetime import timedelta
    cutoff = (datetime.now() - timedelta(days=days)).isoformat()
    
    return [h for h in history if h.get("timestamp", "") >= cutoff]


def print_summary():
    """ì‹¤í–‰ ê¸°ë¡ ìš”ì•½ ì¶œë ¥"""
    recent = get_recent_executions(7)
    
    if not recent:
        print("[INFO] ìµœê·¼ 7ì¼ê°„ ì‹¤í–‰ ê¸°ë¡ì´ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    print("\n" + "=" * 60)
    print("ğŸ“Š ìµœê·¼ 7ì¼ê°„ ìŠ¤í¬ë˜í¼ ì‹¤í–‰ ê¸°ë¡")
    print("=" * 60)
    
    total_articles = sum(r.get("total_articles", 0) for r in recent)
    success_count = sum(1 for r in recent if r.get("success", False))
    
    print(f"\nì‹¤í–‰ íšŸìˆ˜: {len(recent)}íšŒ (ì„±ê³µ: {success_count}íšŒ)")
    print(f"ì´ ìˆ˜ì§‘ ê¸°ì‚¬: {total_articles}ê°œ")
    
    print("\n[ì¼ë³„ ê¸°ë¡]")
    for r in recent[-7:]:
        status = "âœ…" if r.get("success") else "âŒ"
        print(f"  {r.get('date', 'N/A')} {r.get('time', '')}: {status} {r.get('total_articles', 0)}ê°œ")
    
    print("=" * 60)


if __name__ == "__main__":
    print_summary()
