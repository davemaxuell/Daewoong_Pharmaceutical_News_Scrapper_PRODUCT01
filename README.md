# ğŸ¥ Pharmaceutical News Agent (ì œì•½ ë‰´ìŠ¤ ì—ì´ì „íŠ¸)

An automated pharmaceutical and regulatory news scraping, AI summarization, and email distribution system.

## ğŸ“‹ Overview

This system collects pharmaceutical news from multiple Korean and international sources, analyzes them using Google Gemini AI, and distributes summarized news to relevant teams via email.

### Key Features

- **Multi-Source Scraping**: Collects news from 15+ sources (Korean FDA, industry journals, international regulators)
- **AI-Powered Analysis**: Uses Google Gemini for summarization, classification, and team routing
- **Keyword Classification**: Automated categorization based on pharmaceutical keywords
- **Email Distribution**: Team-based news distribution with HTML formatting
- **Regulatory Monitoring**: Tracks updates from ICH, PMDA, FDA, and other regulators

## ğŸ› ï¸ Installation

```bash
# Clone the repository
git clone https://github.com/davemaxuell/Daewoong_Pharmaceutical_News_Scrapper_PRODUCT01.git
cd Daewoong_Pharmaceutical_News_Scrapper_PRODUCT01

# Create virtual environment
python -m venv .venv

# Activate (Windows)
.\.venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt
```

## âš™ï¸ Configuration

Create a `.env` file in the project root:

```env
# Google Gemini API
GEMINI_API_KEY=your_gemini_api_key

# Email Configuration (optional)
EMAIL_SENDER=your_email@gmail.com
EMAIL_PASSWORD=your_app_password
SMTP_SERVER=smtp.gmail.com
SMTP_PORT=587

# openFDA API (optional, for FDA Drug Recalls)
OPENFDA_API_KEY=your_openfda_key
```

## ğŸš€ Usage

### Run Full Pipeline

```bash
python run_pipeline.py
```

This executes:
1. **Phase 1**: Multi-source news scraping + AI summarization
2. **Phase 2**: Regulatory monitoring (ICH, PMDA)
3. **Phase 3**: Email distribution

### Run Individual Components

```bash
# Scrape news only
python multi_source_scraper.py

# AI Summarization only
python ai_summarizer_gemini.py -i news_file.json

# Monitoring only
python monitor_pipeline.py
```

## ğŸ“° Supported News Sources

### Korean Sources
| Source | Type | Description |
|--------|------|-------------|
| DailyPharm | News | ë°ì¼ë¦¬íŒœ ì œì•½ë‰´ìŠ¤ |
| Yakup | News | ì•½ì—…ì‹ ë¬¸ |
| KPANews | News | ëŒ€í•œì•½ì‚¬íšŒ ë‰´ìŠ¤ |
| MFDS | RSS | ì‹í’ˆì˜ì•½í’ˆì•ˆì „ì²˜ (40+ feeds) |
| KPBMA | News | ì œì•½ë°”ì´ì˜¤í˜‘íšŒ |

### International Sources
| Source | Type | Description |
|--------|------|-------------|
| FDA Recalls | API | openFDA Drug Enforcement API |
| EDQM | Web | European quality standards |
| EudraLex | Web | EU GMP guidelines |
| ICH | Web | International harmonization |
| PMDA | Web | Japan pharmaceutical agency |
| GMP Journal | Web | GMP regulatory news |
| PICS | RSS | Pharmaceutical inspection |

## ğŸ“ Project Structure

```
â”œâ”€â”€ run_pipeline.py          # Main pipeline orchestrator
â”œâ”€â”€ multi_source_scraper.py  # Multi-source news collector
â”œâ”€â”€ ai_summarizer_gemini.py  # AI summarization (Gemini)
â”œâ”€â”€ email_sender.py          # Email distribution
â”œâ”€â”€ monitor_pipeline.py      # Regulatory monitoring
â”œâ”€â”€ keywords.py              # Keyword classification rules
â”œâ”€â”€ team_definitions.py      # Team routing definitions
â”œâ”€â”€ scrapers/                # Individual scraper modules
â”‚   â”œâ”€â”€ base_scraper.py      # Base scraper class
â”‚   â”œâ”€â”€ dailypharm_scraper.py
â”‚   â”œâ”€â”€ yakup_scraper.py
â”‚   â”œâ”€â”€ kpanews_scraper.py
â”‚   â”œâ”€â”€ mfds_scraper.py
â”‚   â”œâ”€â”€ kpbma_scraper.py
â”‚   â”œâ”€â”€ edqm_scraper.py
â”‚   â”œâ”€â”€ eudralex_scraper.py
â”‚   â”œâ”€â”€ fda_warning_scraper.py  # FDA Recalls via openFDA
â”‚   â”œâ”€â”€ gmpjournal_scraper.py
â”‚   â”œâ”€â”€ pics_scraper.py
â”‚   â”œâ”€â”€ pmda_scraper.py
â”‚   â””â”€â”€ ich_news_scraper.py
â””â”€â”€ logs/                    # Log files
```

## ğŸ”§ Key Components

### 1. Multi-Source Scraper
Collects news from all enabled sources with keyword filtering:
```python
from multi_source_scraper import MultiSourceScraper
scraper = MultiSourceScraper()
articles = scraper.fetch_all(days_back=1)
```

### 2. AI Summarizer (Gemini)
Analyzes articles and generates:
- Summary (2-3 sentences)
- Key points
- Industry impact
- Target teams
```python
from ai_summarizer_gemini import summarize_all_articles
summarize_all_articles("news.json", "summarized.json")
```

### 3. Keyword Classification
Automatic categorization based on:
- Policy/Regulation
- R&D/Clinical
- Product launches
- Market/Investment
- Company-specific news

## ğŸ“Š Output Format

```json
{
  "title": "Article Title",
  "link": "https://...",
  "published": "2026-01-07T00:00:00",
  "source": "DailyPharm",
  "summary": "Brief summary...",
  "full_text": "Complete article text...",
  "classifications": ["ì •ì±…/í–‰ì •", "ì—…ê³„/R&D"],
  "matched_keywords": ["FDA", "ì„ìƒì‹œí—˜"],
  "ai_analysis": {
    "ai_summary": "AI-generated summary...",
    "key_points": ["Point 1", "Point 2"],
    "target_teams": ["RAíŒ€", "ì„ìƒíŒ€"]
  }
}
```

## ğŸ“§ Email Distribution

News is automatically routed to relevant teams based on AI analysis:
- **RA Team**: Regulatory updates, guideline changes
- **Clinical Team**: Clinical trial news
- **BD Team**: Market, investment news
- **QA Team**: Quality, GMP updates

## â° Scheduling

### Windows Task Scheduler
Use `run_daily_scraper.bat` or create a scheduled task.

### Cron (Linux)
```bash
0 8 * * 1-5 cd /path/to/project && python run_pipeline.py
```

### GitHub Actions
See `.github/workflows/` for automation examples.

## ğŸ”‘ API Keys Required

| Service | Required | Purpose |
|---------|----------|---------|
| Google Gemini | âœ… Yes | AI summarization |
| openFDA | âšª Optional | FDA drug recalls |
| Email SMTP | âšª Optional | Email distribution |

## ğŸ“ License

MIT License

## ğŸ‘¥ Contributors

- Daewoong Pharmaceutical IT Team
